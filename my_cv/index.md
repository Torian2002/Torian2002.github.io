# My_CV

<div style="text-align: center;">
<h2>Jiabo Tong</h2>
Beijing University of Posts and Telecommunications / Queen Mary University of London<br>
Phone: (+86) 15911063236 &nbsp;&nbsp; Email: tongjiabo159@gmail.com  
</div>

## Education

<div style="display: flex; justify-content: space-between;">
  <span><b>Beijing University of Posts and Telecommunications</b></span>
  <span>Beijing, China</span>
</div>
<div style="margin-left: 10px;">- Bachelor of Management <span style="float: right;">2025 (Expected)</span></div>

<div style="display: flex; justify-content: space-between;">
  <span><b>Queen Mary University of London</b></span>
  <span>London, UK</span>
</div>
<div style="margin-left: 10px;">- Bachelor of Engineering <span style="float: right;">2025 (Expected)</span></div>


**Core Courses**:  
Fundamentals of Western Law (100), Physics Experiment C (95), Design & Building (95), Operations Research (94), Probability and Statistics (94), Engineering Mathematics (93), College Computing (93), Advanced Java Programming (93), Western Economics (93), Database Principles (92), Python Data Visualization (92), Basic Programming (91), Signals and Systems (89), Algorithms and Data Structures (89), Internet Protocols (89)  

**GPA**: 3.74/4 &nbsp;&nbsp;&nbsp;  **Weighted Average Score**: 89.7/100 (Chinese scoring), 77/100 (UK scoring) &nbsp;&nbsp;  **Rank**: 6/164  

## Internship Experience

<div style="font-size: 16px;">
  <div style="display: flex; justify-content: space-between;">
    <span><b style="font-size: 18px;">National Laboratory of Pattern Recognition</b></span>
    <span>October 2023 - May 2024</span>
  </div>
  <p>Assistant Intern, Institute of Automation, Chinese Academy of Sciences</p>
  <ul>
    <li><b>Research Direction:</b> Mainly involved in the research of Computer Vision (CV) and Spiking Neural Networks (SNN).</li>
    <li><b>CV:</b> Fully understood the principles and architectures of the Yolo and DETR series, with good coding skills, proficient in writing and optimizing relevant code. Have personal insights into traditional model architectures.</li>
    <li><b>SNN:</b> Proficient in LIF, IF principles and the method of backpropagation training using substitute functions, clearly understanding the advantages and limitations of SNN model architectures. Understand the differences between SNN and ANN (Artificial Neural Network) in terms of coding and training, with experience in using Pytorch and SpikingJelly frameworks.</li>
    <li><b>Paper Research Skills:</b> Conducted thorough research and analysis on the transformation of the Transformer architecture to SNN.</li>
    <li><b>Coding Skills:</b> Proficient in using Linux servers for model development and training. Trained on the CIFIA_100 dataset with MS-ResNet models; participated in converting BERT to SNN architecture using knowledge distillation; independently completed the transformation of the RT_DETR model to SNN architecture; participated in the SNN transformation of the YoloV3 model and the integration of the self-attention mechanism.</li>
  </ul>

  <div style="display: flex; justify-content: space-between;">
    <span><b style="font-size: 18px;">Future Network Theory and Applications Laboratory</b></span>
    <span>May 2023 - October 2023</span>
  </div>
  <p>Assistant Intern, Beijing University of Posts and Telecommunications</p>
  <ul>
    <li>Mastered basic research techniques, deeply studied computer networking and artificial intelligence related papers, establishing a scientific knowledge base and developing basic scientific thinking and paper writing skills. Understood the core principles of network communication architecture and gained deep insights into network communication experiments.</li>
    <li>Used C language to encapsulate code for IPv6 network fluctuation testing experiments and assisted in organizing related experiments. Assisted in designing the application of Q learning in the SDN direction, helping to adjust model code and train models.</li>
  </ul>
</div>

## Research Experience

<div style="font-size: 16px;">
  <div style="display: flex; justify-content: space-between;">
    <span><b>Machine Learning and Business Analytics</b></span>
    <span>December 2022 - February 2023</span>
  </div>
  <p>Massachusetts Institute of Technology (Online)</p>
  <ul>
    <li>Studied supervised and unsupervised machine learning algorithms, such as linear regression, logistic regression, decision trees, support vector machines, and artificial neural networks.</li>
    <li><b>Maritime Commodity Forecasting:</b> Utilized the global AIS dataset to apply decision tree algorithms for predicting commodities transported by energy cargo ships, focusing on details like the origin, destination, and draft depth. Achieved a prediction accuracy of 73% for the 2010-2015 dataset. Confident in the ability to further improve model accuracy with more complex decisions or more data.</li>
    <li><b>Mortgage Loan Decision Analysis:</b> Used a dataset of 600,000 mortgage samples from Fannie Mae and Freddie MAC (2000-2006), combined with interest rate indicators from the St. Louis Federal Reserve. Applied logistic regression for decision-making on 30-year fixed-rate mortgages for single households, achieving an 88% decision accuracy rate. Achieved the best confusion matrix result in the team: 96% Recall and 93% Precision.</li>
  </ul>

  <div style="display: flex; justify-content: space-between;">
    <span><b>Residual Block Training for Spiking Neural Networks</b></span>
    <span>November 2023 - December 2023</span>
  </div>
  <p>Institute of Automation, Chinese Academy of Sciences</p>
  <ul>
    <li>The MS-ResNet network allowed for training of deep SNN-based models beyond 32 layers for the first time without degradation or explosion of gradients. Conducted auxiliary confirmation training on the CIFAR-100 dataset for the MS-ResNet architecture with a batch size of 128 for the Resnet-108 SNN model, achieving an average loss of 5%, surpassing previous records.</li>
  </ul>

  <div style="display: flex; justify-content: space-between;">
    <span><b>SNN Transformation of the RT_DETR Model</b></span>
    <span>February 2024 - March 2024</span>
  </div>
  <p>Institute of Automation, Chinese Academy of Sciences</p>
  
  <ul style="list-style-position: left;">
    <li>The RT_DETR marks the first time the DETR series has been capable of real-time processing. Through an in-depth analysis of the model's overall architecture, I improved the newly introduced AIFI and CCFM modules, adapting them to SNN (Spiking Neural Network) mode for data processing and calculations. This adaptation also applies to the model's decoder part using the Deformable Self-Attention mechanism, and comparative experiment analysis has been completed. To our knowledge, this is the first attempt to introduce SNN mode in the DETR series.</li>
  </ul>

  <div style="display: flex; justify-content: space-between;">
    <span><b>Enhanced Feature Fusion in EMS_Yolo</b></span>
    <span>March 2024 - April 2024</span>
  </div>
  <p>Institute of Automation, Chinese Academy of Sciences</p>
  <ul>
    <li>This project was established on the basis of EMS_Yolo (i.e., the SNN version of YoloV3). In the process of handling cross-scale feature fusion, I introduced the SA (Self-Attention) mechanism to enhance the modeling capability of global image positioning. All these steps were implemented using the SNN version. We conducted comparative tests using the EMS_Yolo as a benchmark. The model performance reached SOTA using the SNN version of Resnet18 as the Backbone.</li>
  </ul>
</div>
  

## Honors and Awards

<div>
<div style="display: flex; justify-content: space-between;">
  <span><b style="font-size: 16px;">· First Class Scholarship (4/177)</b></span>
  <span>October 2022</span>
</div>
<div style="display: flex; justify-content: space-between;">
  <span><b style="font-size: 16px;">· Merit Student</b></span>
  <span>October 2022</span>
</div>
<div style="display: flex; justify-content: space-between;">
  <span><b style="font-size: 16px;">· National Second Prize in Chinese University Student Mathematics Competition</b></span>
  <span>December 2022</span>
</div>
<div style="display: flex; justify-content: space-between;">
  <span><b style="font-size: 16px;">· Double Silver Medalist in the 57th Sports Meeting of BUPT in 5000m and 1500m events</b></span>
  <span>May 2023</span>
</div>
<div style="display: flex; justify-content: space-between;">
  <span><b style="font-size: 16px;">· Seventh Place in Beijing Colleges Marathon Relay</b></span>
  <span>June 2023</span>
</div>
<div style="display: flex; justify-content: space-between;">
  <span><b style="font-size: 16px;">· First Class Scholarship (3/167)</b></span>
  <span>October 2023</span>
</div>
<div style="display: flex; justify-content: space-between;">
  <span><b style="font-size: 16px;">· Merit Student</b></span>
  <span>October 2023</span>
</div>

</div>

## Skills

<div>
<div style="display: flex; justify-content: space-between;">
  <span><b style="font-size: 16px;">· Programming:</b></span>
  <span>Java, C, JavaScript, Python</span>
</div>
<div style="display: flex; justify-content: space-between;">
  <span><b style="font-size: 16px;">· Operating Systems:</b></span>
  <span>MacOS, Linux, Windows</span>
</div>
<div style="display: flex; justify-content: space-between;">
  <span><b style="font-size: 16px;">· Language:</b></span>
  <span>English (CET4-Oral A, CET6 546, IELTS 7.0)</span>
</div>
<div style="display: flex; justify-content: space-between;">
  <span><b style="font-size: 16px;">· Other Skills:</b></span>
  <span>MySQL, Anaconda, Pytorch, tmux, Microsoft Office</span>
</div>
</div>

